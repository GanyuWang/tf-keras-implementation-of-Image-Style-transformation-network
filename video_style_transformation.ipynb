{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_style_transformation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIn1vXyyi3DI"
      },
      "source": [
        "# Use the style transformation network to do a video transformation. \n",
        "\n",
        "download the style image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko4H0o8h1jLO",
        "outputId": "4ca19b2e-ee80-4748-e09d-b4ada8646644"
      },
      "source": [
        "!wget http://107.172.22.247/NST/impression_sunrise.jpg\n",
        "\n",
        "!wget http://107.172.22.247/NST/3.jpg\n",
        "\n",
        "!mkdir checkpoint\n",
        "!mkdir model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-30 21:58:40--  http://107.172.22.247/NST/impression_sunrise.jpg\n",
            "Connecting to 107.172.22.247:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29745 (29K) [image/jpeg]\n",
            "Saving to: ‘impression_sunrise.jpg’\n",
            "\n",
            "\rimpression_sunrise.   0%[                    ]       0  --.-KB/s               \rimpression_sunrise. 100%[===================>]  29.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-30 21:58:40 (851 KB/s) - ‘impression_sunrise.jpg’ saved [29745/29745]\n",
            "\n",
            "--2020-11-30 21:58:40--  http://107.172.22.247/NST/3.jpg\n",
            "Connecting to 107.172.22.247:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15606 (15K) [image/jpeg]\n",
            "Saving to: ‘3.jpg’\n",
            "\n",
            "3.jpg               100%[===================>]  15.24K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-30 21:58:40 (454 KB/s) - ‘3.jpg’ saved [15606/15606]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0OUhdackZVh"
      },
      "source": [
        "build the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he6kjwGgz9hm",
        "outputId": "064e3d54-0f14-4177-8558-5406f9c3c36c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Nov 27\n",
        "\n",
        "@author: Ganyu Wang\n",
        "\n",
        "Train Draft 4\n",
        "\n",
        "use the dataset intel recognition. \n",
        "\n",
        "train a identify transformation model. \n",
        "\n",
        "save model, reconstructruct model.\n",
        "\n",
        "Write the custom loss function again. \n",
        "    the custom loss function should return the \n",
        "\n",
        "Predict.\n",
        "Visualization. \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#%% build models\n",
        "\n",
        "def residual_block(y, nb_channels, _strides=(1, 1), _project_shortcut=False):\n",
        "    shortcut = y\n",
        "\n",
        "    # down-sampling is performed with a stride of 2\n",
        "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.LeakyReLU()(y)\n",
        "\n",
        "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "\n",
        "    # identity shortcuts used directly when the input and output are of the same dimensions\n",
        "    if _project_shortcut or _strides != (1, 1):\n",
        "        # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
        "        # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
        "        shortcut = layers.Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    y = layers.add([shortcut, y])\n",
        "    y = layers.LeakyReLU()(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "def Identical_transform_model(y):\n",
        "    \"\"\"\n",
        "    transform_model, channel last, \n",
        "        input  (batch_size, width, height, channel) -> (BS, 256, 256, 3)\n",
        "        output (batch_size, width, height, channel) -> (BS, 256, 256, 3)\n",
        "    \n",
        "    \"\"\"\n",
        "    d = Conv2D(32, (9, 9), input_shape=(256, 256, 3), padding='same', activation='relu')(y)\n",
        "    d = Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(d)\n",
        "    d = Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(d)\n",
        "    d = residual_block(d, 128)\n",
        "    d = residual_block(d, 128)\n",
        "    d = residual_block(d, 128)\n",
        "    d = residual_block(d, 128)\n",
        "    d = residual_block(d, 128)\n",
        "    d = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=2)(d)\n",
        "    d = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', strides=2)(d)\n",
        "    d = Conv2DTranspose(3, (9, 9), activation='relu', padding='same', strides=1)(d)\n",
        "    \n",
        "    return d\n",
        "\n",
        "inputs = keras.Input(shape=(256, 256, 3))\n",
        "outputs = Identical_transform_model(inputs)\n",
        "transform_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE8MaLYECF9E"
      },
      "source": [
        "** Upload the weight h5 file here ** \n",
        "\n",
        "It takes 1 minutes in google colab. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLy5_XId0GNk"
      },
      "source": [
        "transform_model.load_weights(\"model_draft_6.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anpfd14YBOPH"
      },
      "source": [
        "#%% predict \n",
        "\n",
        "test_img = load_image(\"3.jpg\")\n",
        "pred_img = transform_model.predict(test_img)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(test_img[0,])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(pred_img[0,])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "542LdTlKiQEZ"
      },
      "source": [
        "Download video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll2pJfBKwJV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362c244d-845d-403b-8533-e111cf3270bd"
      },
      "source": [
        "!wget http://107.172.22.247/NST/video.mp4\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-30 22:02:09--  http://107.172.22.247/NST/video.mp4\n",
            "Connecting to 107.172.22.247:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1570024 (1.5M) [video/mp4]\n",
            "Saving to: ‘video.mp4’\n",
            "\n",
            "\rvideo.mp4             0%[                    ]       0  --.-KB/s               \rvideo.mp4           100%[===================>]   1.50M  7.94MB/s    in 0.2s    \n",
            "\n",
            "2020-11-30 22:02:09 (7.94 MB/s) - ‘video.mp4’ saved [1570024/1570024]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhkvJAwwia4v"
      },
      "source": [
        "load the video for style transfer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MKq4JETwSc7"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Create a VideoCapture object and read from input file\n",
        "# If the input is the camera, pass 0 instead of the video file name\n",
        "cap = cv2.VideoCapture('video.mp4')\n",
        "\n",
        "video = []\n",
        "\n",
        "# Check if camera opened successfully\n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "# Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "  # Capture frame-by-frame\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    resized_frame = cv2.resize(frame, (256, 256))\n",
        "\n",
        "    video.append(resized_frame)\n",
        "    \n",
        "\n",
        "  # Break the loop\n",
        "  else: \n",
        "    break\n",
        "\n",
        "# When everything done, release the video capture object\n",
        "cap.release()\n",
        "\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "video = np.array(video) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wQLaydDijG3"
      },
      "source": [
        "Do the style transfer for the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V0ZbG5G2Bq8"
      },
      "source": [
        "transfer_video = transform_model.predict(video)\n",
        "transfer_video *= 255\n",
        "transfer_video = transfer_video.astype(np.uint8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwZffFo6ipnQ"
      },
      "source": [
        "Output the transfered video. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbxhfZY__VHU"
      },
      "source": [
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4',fourcc, 30, (256,256)) # fps, (size)\n",
        "\n",
        "for i in range(transfer_video.shape[0]):    \n",
        "    frame = transfer_video[i]\n",
        "\n",
        "    # write the flipped frame\n",
        "    out.write(frame)\n",
        "\n",
        "\n",
        "# Release everything if job is finished\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}